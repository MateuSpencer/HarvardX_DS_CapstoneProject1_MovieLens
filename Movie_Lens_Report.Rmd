---
title: '*MovieLens Recommendation System Report*'
subtitle: '***HarvardX Data Science Professional Certificate: PH125.9x Capstone Project 1***'
author: "Mateus Spencer"
date: "_`r format(Sys.Date(), '%d %B, %Y')`_"
output: pdf_document
fontsize: 12pt
include-before: '`\newpage{}`{=latex}'
urlcolor: blue
---

\newpage

```{r setup, include = FALSE}
if (!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if (!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if (!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(ggplot2)
library(caret)
library(dplyr)
library(knitr)
```

# 1.	Introduction
Recommendation systems have the goal of predicting a user's rating or preference towards a certain item. They can be applied on a wide range of domains such as, music, books, search queries, movies, restaurants and products in general. They offer great value to companies that handle big amounts of data, as they are able to improve a users experience and consequently drive up the companies revenues.

In this project we will use the MovieLens dataset, generated by the GroupLens research lab, to train a Model for predicting movie ratings and evaluating the RMSE of the evolution of the model to asses its performance.

## 1.1 The Dataset

The full MovieLens dataset can be found here: https://grouplens.org/datasets/movielens/latest/. The Full dataset now has  approximately 33,000,000 entries (07/01/2024), but we will be using a subset of only 10,000,000 entries to be able to train the models on a laptop, it can be downlodade at: https://grouplens.org/datasets/movielens/10m/.
Running the code provided by HarvardX the dataset is split into two datasets, edx having 90% used to train the model  and final_holdout_test with 10% of the data used only for final evaluation.

```{r edX Code, include=FALSE}
# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

options(timeout = 120)

dl <- "ml-10M100K.zip"
if(!file.exists(dl))
  download.file("https://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings_file <- "ml-10M100K/ratings.dat"
if(!file.exists(ratings_file))
  unzip(dl, ratings_file)

movies_file <- "ml-10M100K/movies.dat"
if(!file.exists(movies_file))
  unzip(dl, movies_file)

ratings <- as.data.frame(str_split(read_lines(ratings_file), fixed("::"), simplify = TRUE),
                         stringsAsFactors = FALSE)
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
ratings <- ratings %>%
  mutate(userId = as.integer(userId),
         movieId = as.integer(movieId),
         rating = as.numeric(rating),
         timestamp = as.integer(timestamp))

movies <- as.data.frame(str_split(read_lines(movies_file), fixed("::"), simplify = TRUE),
                        stringsAsFactors = FALSE)
colnames(movies) <- c("movieId", "title", "genres")
movies <- movies %>%
  mutate(movieId = as.integer(movieId))

movielens <- left_join(ratings, movies, by = "movieId")

# Final hold-out test set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") 

test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in final hold-out test set are also in edx set
final_holdout_test <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from final hold-out test set back into edx set
removed <- anti_join(temp, final_holdout_test)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```


```{r str, echo = FALSE, include=FALSE}
str(edx)
```
By analyzing the structure of the dataset we observe that it has 6 variables that are described in the table below:

```{r dataset structure summary, echo = FALSE}

structure_table <- data.frame(
  Name =c("`userId`", 
          "`movieId`", 
          "`rating`", 
          "`timestamp`", 
          "`title`", 
          "`genres`"),

  Format =c("Integer", 
            "Integer",
            "Numerical", 
            "Integer", 
            "Character string", 
            "Character string"),

  Description = c("Unique numerical identifier for each user", 
                  "Unique numerical identifier", 
                  "Rating given to a movie by a user, starting at 0 and going up to 5 in steps of 0.5", 
                  "Unix epoch of the date/time of the rating (number of seconds since 1-Jan-1970.", 
                  "Name of the Movie & year of release",
                  "Genres the movie belongs to, separated by |"))

kable(structure_table,  align = 'c')

```

\newpage    
Here are some of the first entries of the edx dataset:

```{r First 5 rows of edx data set, echo = FALSE}
kable(head(edx),  align = 'c')
```

Below are some metrics of each of the datasets that show that they are evenly distributed
```{r edx set summary , echo = FALSE}

edx_summary <- data.frame(rows_number = nrow(edx), 
                users_number= n_distinct(edx$userId),
                movies_number = n_distinct(edx$movieId),
                average_rating = round(mean(edx$rating),3),
                first_rating_Date = as.Date(as.POSIXct(min(edx$timestamp), origin = "1970-01-01")),
                last_rating_date = as.Date(as.POSIXct(max(edx$timestamp), origin = "1970-01-01")))

kable(edx_summary, caption = "edx dataset summary",  align = 'c')
```



```{r final_holdout_test set summary , echo = FALSE}
final_holdout_test_summary <- data.frame(rows_number = nrow(final_holdout_test),
                              users_number= n_distinct(final_holdout_test$userId),
                              movies_number = n_distinct(final_holdout_test$movieId),
                              average_rating = round(mean(final_holdout_test$rating),3),
                              first_rating_Date = as.Date(as.POSIXct(min(final_holdout_test$timestamp), origin = "1970-01-01")),
                              last_rating_date = as.Date(as.POSIXct(max(final_holdout_test$timestamp), origin = "1970-01-01")))

kable(final_holdout_test_summary, caption = "final_holdout_test dataset summary",  align = 'c')
```


## 1.2	 Project methodology
This work will start by firstly doing an exploratory analysis of the dataset in order to gain a better understanding of the data and figure out what variables are more valuable and should be used in the models.
After that we will start to develop the model by starting with a simple model and iterating over it to improve it by lowering the RMSE to evaluate the model with the final_holdout_test dataset.The target RMSE to reach will be 0.86490.

```{r RMSE target, echo=FALSE}
target_rmse <- 0.86490
```

\newpage
# 2.	Analysis and Exploration

in the following sections we will analyze each feature individually in order to decide which ones provide the most information and should be firstly implemented in the model.


## 2.1 Ratings Exploration

The rating is an ordinal scale of number from 0.5 to 5 in steps of 0.5 given by the users who watched the movie.
Here we can see a histogram of the distribution of all the ratings with the red line representing the mean.

```{r Overall ratings distribution, echo = FALSE}
edx %>%
  ggplot(aes(x= rating)) +
  geom_histogram( bins = 10, color = "blue") +
  scale_x_continuous(breaks=seq(0, 5, by= 0.5)) +
  ggtitle("Ratings distribution")+
  labs(x="Rating", y="number of ratings") +
  geom_vline(xintercept = mean(edx$rating),  colour = "red")
```
  We can conclude:

•   The overall average rating in the edx dataset was `r round(mean(edx$rating), 2)` 

•   The top 3 ratings from most to least are :  4, 3, 5.

•   There is a propensity for users to give higher ratings to movies.

•   It is also clear that the ratings between full numbers are less popular than their counterparts.


## 2.2 Movies Exploration
The edx dataset has total of `r n_distinct(edx$movieId)` movies.
Below is a histogram of the distribution of number of ratings per movies.
The graph if presented in a logarithmic scale becacuse it is much more common for movies to have fewer ratings, but some outliers with more that 10,000  ratings stretch out the histogram too much making the bins for less rated per movies too big for their variation.
```{r Number of ratings per movie distribution, echo = FALSE}
###### Figure 2: Histogram of number of ratings by movies in Edx Dataset
edx %>% 
  group_by(movieId) %>%
  summarize(num_movie_ratings = n()) %>% 
  ggplot(aes(x = num_movie_ratings))+
  geom_histogram(bins = 40, color = "blue")+
  scale_x_log10() +
  ggtitle("Number of ratings per movie distribution") +
  labs(x="Ratings per Movie (log10)", y="Number of Movies") +
  geom_vline(aes(xintercept = mean(num_movie_ratings)), color = "red")
```
The following histogram of the distribution of the average rating per movie is in accordance with the ratings histogram, but the mean eliminated the preference for whole numbers.
```{r Average Rating per Movie distribution, echo = FALSE}
edx %>% 
  group_by(movieId) %>%
  summarise(movie_avg_ratings = sum(rating)/n()) %>%
  ggplot(aes(x = movie_avg_ratings)) +
  geom_histogram(bins=20, color = I("blue")) +
  scale_x_continuous(breaks=seq(0, 5, by= 0.5)) +
  ggtitle("Average Rating per Movie distribution") +
  labs(x="Average Rating per Movie (log10)", y="Number of Movies")
```
Here, we can see that there is a bigger variation of the average rating among movies with a lower number of ratings.
We also see that the average rating of movies increases with the number of ratings given to a movie, which would make sense since people prefer to watch good movies and will prefer to watch those, and there fore giving them more ratings.

```{r movie avg. rating vs number of rarings, echo = FALSE, warning=FALSE, message=FALSE}
edx %>% 
  group_by(movieId) %>%
  summarise(num_movie_ratings = n(),
            movie_avg_ratings = sum(rating)/n()) %>%
  sample_frac(0.2) %>%
  ggplot(aes(x = num_movie_ratings, y = movie_avg_ratings)) +
  geom_point(color = "blue") +
  geom_smooth(color = "green") +
  ggtitle("Number of Ratings vs. Average Rating per Movie") +
  labs(x = "Number of Ratings", y = "Average Rating per Movie")
```

## 2.3	User Exploration

The edx dataset has `r n_distinct(edx$userId)` users represented by userid. The following histogram represent the number of ratings by user with the x axis again in logarithmic scale to mitigate the stretching out of the histogram by outliers wit a lot of ratings:

```{r Number of ratings by users, echo=FALSE}
edx %>% 
  group_by(userId) %>%
  summarize(num_user_ratings = n()) %>% 
  ggplot(aes(x = num_user_ratings))+
  geom_histogram(bins = 40, color = "blue")+
  scale_x_log10()+
  ggtitle("Number of ratings by users distribution") +
  labs(x = "Number of ratings per User (log10)", y = "Number of Users")+
  geom_vline(aes(xintercept = mean(num_user_ratings)), color = "red")
```
As in the movies average rating histogram here we also see a similarity to the ratings histogram without the bias towards whole numbers.

```{r Users average rating, echo=FALSE}
edx %>% 
  group_by(userId) %>%
  summarise(user_avg_ratings = sum(rating)/n()) %>%
  ggplot(aes(user_avg_ratings)) +
  geom_histogram(bins=20, color = I("blue")) +
  scale_x_continuous(breaks=seq(0, 5, by= 0.5)) +
  ggtitle("Users average rating Distribution") +
  labs(x="User average rating", y="Number of users")
```
To conclude, in this plot we see again a larger diversity in average rating for movies for users with fewer ratings, nut in this case there is no increase in average rating with the number of ratings.

```{r user avg. rating vs number of rarings, echo = FALSE, warning=FALSE, message=FALSE}
edx %>% 
  group_by(userId) %>%
  summarise(num_user_ratings = n(),
            user_avg_ratings = sum(rating)/n()) %>%
  sample_frac(0.2) %>%
  ggplot(aes(x = num_user_ratings, y = user_avg_ratings)) +
  geom_point(color = "blue") +
  geom_smooth(color = "green") +
  ggtitle("Number of Ratings vs. Average Rating per User") +
  labs(x = "Number of Ratings", y = "Average Rating per User")

```

## 2.4	 Time effect Exploration
By exploring the time at which a rating was given we can explore if the average rating per movie has a correlation to the time at which it was given. From the plot bellow we see a slight decrease over the years with a small climb since 2005 in the average of ratings given out in a certain month, however, this variation happens in  a very narrow window  between 3.7 and 3.4 rating therefore not being very relevant. We see however a noticeable increase in consistency of ratings between months.

```{r Average ratings of Month, echo=FALSE, message=FALSE}
edx %>%
  mutate(month = round_date(as_datetime(timestamp), unit = "month")) %>%
  group_by(month) %>%
  summarize(avg_ratings = mean(rating)) %>%
  ggplot(aes(x = month, y = avg_ratings)) +
  geom_point() +
  geom_smooth(color = "blue") +
  ggtitle("Average ratings of Month") +
  labs(x = "Month",y = "Average Rating")
```
As for the number of ratings per month overtime we see a general consistency marked by very agresive spikes in certain periods. This coulb be explained due to the release of very popular movies that gather a lot of ratings, which people would watch on the relsease nonth and the following months.

```{r Number of Ratings per Month, echo=FALSE, message=FALSE}
edx %>%
  mutate(month = round_date(as_datetime(timestamp), unit = "month")) %>%
  group_by(month) %>%
  summarize(num_ratings = n()) %>%
  ggplot(aes(x = month, y = num_ratings)) +
  geom_point() +
  geom_smooth(color = "blue") +
  ggtitle("Number of Ratings per Month") +
  labs(x = "Month",y = "Number of Ratings")
```

## 2.5	 Genres Exploration
A movie could be classified to one or more genres.
There are `r n_distinct(edx$genre)` genre combinations for the movies in the dataset.

The genre variable contains all the genres the movie is characterized in, within twenty different classifications.

```{r all genres, echo=FALSE}
str_extract_all(unique(edx$genres), "[^|]+") %>%
  unlist() %>%
  unique()
```
We will be analyzing each genre independentluy to asses if there is any preference for certinn genres.

```{r separate genres, echo = FALSE}
  edx_genres <- edx %>% 
    separate_rows(genres, sep = "\\|", convert = TRUE) %>%
    group_by(genres) %>%
    summarize( num_ratings_genre = n(), avg_ratings_genre = mean(rating))
```


In this bar plot we see that there is a general preference for certain genres over others.

```{r number of ratings per Genre, echo = FALSE}
edx_genres$genres <- reorder(edx_genres$genres, -edx_genres$num_ratings_genre)

ggplot(edx_genres, aes(x = genres, y = num_ratings_genre)) +
  geom_bar(stat = "identity", color = "blue") +
  labs(title = "Number of Ratings per Genre", x = "Genre", y = "Number of Ratings") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

By looking at both plots we can see that some of the genres with the lowest amounts of ratings have some of the highest average ratings, this could be due to the fact of them being more niche genres whose movies are mostly seen by people who enjoy those genres and will naturally give out higher ratings.

```{r avg ratiung per genre, echo = FALSE}
edx_genres$genres <- reorder(edx_genres$genres, -edx_genres$avg_ratings_genre)

ggplot(edx_genres, aes(x = genres, y = avg_ratings_genre)) +
  geom_bar(stat = "identity", color = "blue") +
  labs(title = "Average Rating for Each Genre", x = "Genre", y = "Average Rating") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  coord_cartesian(ylim = c(3, NA))

```
Although there is some significant variation in the average ratings between genres it is not as significant as the variation in other features such as movies and users average ratings therefore we will not prioritize the inclusion of this feature in our model as much.
We should also note that due to the complexity of all of the combinations of genres for each movies building an effective model with the genres would require more advanced methods and bigger computing power.

\newpage
# 3. Methodology

## 3.1	Model performance evaluation
To evaluate the evolution of performance of our model, we will use root mean squared error (RMSE) as the loss function.
The RMSE represent the error loss between the predicted ratings derived from applying the model and actual ratings in the test set.

In the formula shown below, $y_{u,i}$ is defined as the actual rating provided by user $i$ for movie $u$, $\hat{y}*{u,i}$ is the predicted rating for the same, and N is the total number of user/movie combinations.
$$RMSE = \sqrt{\frac{1}{N}\sum*{u,i}\left(\hat{y}*{u,i}-y*{u,i}\right)^2}$$

```{r RMSE, echo=FALSE}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```

## 3.2	Modeling Approach
Due to the size of our training model, conventional statistical methods would take too long to compute, therefore we will be using a machine learning approach as discussed in the course.

\newpage
# 4. Results

Based on the exploration of the data described above, we will firstly implement user and movie effects in our model since time and genre effect are more marginal.


## 4.1 Model 1: BaseLine Model

Starting with the Simplest Model as a Baseline:  predicting the same rating regardless of the user, movie or genre.

$$Y_{u,i} = \mu + \epsilon_{u,i}$$
Where $u$ is the index for users, and $i$ for movies.
For this, the estimate for $\mu$ is the average of all ratings, which is `r mean(edx$rating)`.

```{r Method: just the average, echo=FALSE}
mu <- mean(edx$rating)
```

```{r Results Model 1, echo=FALSE, warning=FALSE}
model_1_rmse <- RMSE(final_holdout_test$rating, mu)
rmse_results <- data.frame(Model = "Just the Average", RMSE = model_1_rmse)
kable(rmse_results)
```

As expected the RMSE is not great, but  it gives us a good starting point from where to build our model.

## 4.2 Model 2: Movie effects Model

In this model, the effects of individual movies are considered. The bias for each movie (b_i) is calculated, representing the difference between the average rating of the movie and the overall average rating. This introduces a level of personalization based on movie preferences. While an improvement over the baseline model, it still has limitations, especially in accounting for user-specific preferences.

```{r Modeling movie effects, echo=FALSE, warning=FALSE}
movie_avgs <- edx %>%
  group_by(movieId) %>%
  summarize(b_i = mean(rating - mu))

predicted_rating_m2 <- final_holdout_test %>%
  left_join(movie_avgs, by='movieId') %>%
  mutate(pred = mu + b_i)


model_2_rmse <- RMSE(final_holdout_test$rating, predicted_rating_m2$pred)
rmse_results <- rbind(rmse_results,data.frame(Model = "Movie Effect Model", RMSE = round(model_2_rmse, 4)))

kable(rmse_results[2,])
```


## 4.3 Model 3: Movies and Users effects Model

Building upon the movie effect model, this approach incorporates user-specific biases (b_u). Now, the model considers both movie and user effects to predict ratings. The RMSE is further reduced compared to the previous models, showcasing the importance of accounting for individual user preferences in recommendation systems.

```{r Adding Users effects, echo=FALSE, warning=FALSE}
user_avgs <- edx %>% 
  left_join(movie_avgs, by = 'movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

predicted_rating_m3  <- final_holdout_test %>% 
  left_join(movie_avgs, by = 'movieId') %>%
  left_join(user_avgs, by = 'userId') %>%
  mutate(pred = mu + b_i + b_u)

model_3_rmse  <- RMSE(final_holdout_test$rating, predicted_rating_m3$pred)
rmse_results <- rbind(rmse_results, data_frame(Model="Movie and User Effect model",RMSE = round(model_3_rmse, 4)))
kable(rmse_results[3,])
```

## 4.4 Model 4: Regularization of Movies and Users effects Model

To enhance the predictive performance of our recommendation model, we introduce regularization. Regularization is a technique used to prevent overfitting by adding a penalty term to the model parameters. In our case, regularization is applied to both movie and user effects, represented by b_i and b_u, respectively.

The regularization term imposes a constraint on the magnitude of the biases (b_i and b_u). It discourages extreme values, preventing the model from becoming overly complex and tailored to the training data. This is crucial for generalizing well to unseen data, ensuring that our model doesn't capture noise in the training set.

Lambda, the regularization parameter, controls the strength of the regularization. Choosing an appropriate lambda is a critical step. We systematically explore a range of lambda values and select the one that minimizes the Root Mean Squared Error (RMSE) on our validation set. The plot above displays the relationship between different lambda values and their corresponding RMSE scores. The lambda with the minimum RMSE serves as our optimal regularization parameter.

Benefits of Regularization
Regularization not only improves the model's ability to generalize but also helps in managing bias-variance trade-off. By preventing the model from fitting the training data too closely, it encourages a more balanced and robust model. The regularization technique contributes to the overall effectiveness of our recommendation system by striking a better balance between complexity and simplicity.

```{r find best lambda, echo = FALSE, warning=FALSE}

calculate_rmse <- function(lambda) {
  mu <- mean(edx$rating)

  b_i <- edx %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu) / (n() + lambda))

  b_u <- edx %>%
    left_join(b_i, by = "movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu) / (n() + lambda))

  predicted_ratings <- final_holdout_test %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    .$pred

  return(RMSE(final_holdout_test$rating, predicted_ratings))
}

lambdas <- seq(4, 7, 0.25)

rmses <- sapply(lambdas, calculate_rmse)

qplot(lambdas, rmses) +
  ggtitle("Selecting the tuning parameter") +
  labs(x = "Lambda",
       y = "RMSE")

lambda <- lambdas [which.min(rmses)]
```

Lambda, the regularization parameter, controls the strength of the regularization. Choosing an appropriate lambda is a critical step. We systematically explore a range of lambda values and select the one that minimizes the Root Mean Squared Error (RMSE) on our validation set. The plot above displays the relationship between different lambda values and their corresponding RMSE scores. The lambda with the minimum RMSE (`r lambda`) serves as our optimal regularization parameter.

```{r regularization model, echo = FALSE}

movie_avgs_regularized <- edx %>%
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu) / (n() + lambda))

user_avgs_regularized <- edx %>%
  left_join(movie_avgs_regularized, by = 'movieId') %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - mu - b_i) / (n() + lambda))

predicted_rating_m4 <- final_holdout_test %>%
  left_join(movie_avgs_regularized, by = 'movieId') %>%
  left_join(user_avgs_regularized, by = 'userId') %>%
  mutate(pred = mu + b_i + b_u)

model_4_rmse <- RMSE(final_holdout_test$rating, predicted_rating_m4$pred)

rmse_results <- rbind(rmse_results, data.frame(Model = "Regularized Movie and User Effect Model", RMSE = round(model_4_rmse, 4)))

kable(rmse_results)

```

Since we have surpassed the target RMSE of `r target_rmse` we will not be improving the model any further.


\newpage
# 5. Conculusions

In summary, our exploration and analysis of the MovieLens dataset, coupled with the iterative development of recommendation models, have yielded valuable insights into user behavior and the dynamics of the movie ratings landscape.
Our final model, the Regularized Movie and User Effect Model, successfully surpassed the target RMSE, underscoring its proficiency in predicting user ratings.

To further enhance the performance of our recommendation model, several techniques could be explored, matrix factorization techniques, such as Singular Value Decomposition (SVD) or Alternating Least Squares (ALS). Matrix factorization allows the model to capture latent features and relationships between users and movies, providing a more nuanced understanding of preferences. 

# 6. References
[1] “Introduction to Data Science - Data Analysis and Prediction Algorithms with R”, Dr. Rafael A. Irizarry [link](https://rafalab.github.io/dsbook/)

[2] "R Markdown: The Definitive Guide", Yihui Xie, J. J. Allaire, Garrett Grolemund, 2019-06-03 [link](https://bookdown.org/yihui/rmarkdown/)